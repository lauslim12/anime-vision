{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnimeFaceClassification_MakeImageClassifier_TF2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMtqFsJaXpvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "52e1ba12-7cbb-46da-a96b-6473aff6857e"
      },
      "source": [
        "!pip install \"tensorflow~=2.0\"\n",
        "!pip install \"tensorflow-hub[make_image_classifier]~=0.6\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow~=2.0 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (2.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (3.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (3.12.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.30.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (2.2.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow~=2.0) (49.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.0) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-hub[make_image_classifier]~=0.6 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub[make_image_classifier]~=0.6) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub[make_image_classifier]~=0.6) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub[make_image_classifier]~=0.6) (3.12.2)\n",
            "Requirement already satisfied: keras-preprocessing[image]; extra == \"make_image_classifier\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub[make_image_classifier]~=0.6) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub[make_image_classifier]~=0.6) (49.1.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0; extra == \"image\" in /usr/local/lib/python3.6/dist-packages (from keras-preprocessing[image]; extra == \"make_image_classifier\"->tensorflow-hub[make_image_classifier]~=0.6) (7.0.0)\n",
            "Requirement already satisfied: scipy>=0.14; extra == \"image\" in /usr/local/lib/python3.6/dist-packages (from keras-preprocessing[image]; extra == \"make_image_classifier\"->tensorflow-hub[make_image_classifier]~=0.6) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlRxeem0awGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxgspAn6X8af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7610688e-64ed-4d29-e929-f0da463d2585"
      },
      "source": [
        "!make_image_classifier --helpfull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-19 04:41:09.821527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "\n",
            "       USAGE: /usr/local/bin/make_image_classifier [flags]\n",
            "flags:\n",
            "\n",
            "absl.app:\n",
            "  -?,--[no]help: show this help\n",
            "    (default: 'false')\n",
            "  --[no]helpfull: show full help\n",
            "    (default: 'false')\n",
            "  --[no]helpshort: show this help\n",
            "    (default: 'false')\n",
            "  --[no]helpxml: like --helpfull, but generates XML output\n",
            "    (default: 'false')\n",
            "  --[no]only_check_args: Set to true to validate args and exit.\n",
            "    (default: 'false')\n",
            "  --[no]pdb_post_mortem: Set to true to handle uncaught exceptions with PDB post\n",
            "    mortem.\n",
            "    (default: 'false')\n",
            "  --profile_file: Dump profile information to a file (for python -m pstats).\n",
            "    Implies --run_with_profiling.\n",
            "  --[no]run_with_pdb: Set to true for PDB debug mode\n",
            "    (default: 'false')\n",
            "  --[no]run_with_profiling: Set to true for profiling the script. Execution will\n",
            "    be slower, and the output format might change over time.\n",
            "    (default: 'false')\n",
            "  --[no]use_cprofile_for_profiling: Use cProfile instead of the profile module\n",
            "    for profiling. This has no effect unless --run_with_profiling is set.\n",
            "    (default: 'true')\n",
            "\n",
            "absl.logging:\n",
            "  --[no]alsologtostderr: also log to stderr?\n",
            "    (default: 'false')\n",
            "  --log_dir: directory to write logfiles into\n",
            "    (default: '')\n",
            "  --[no]logtostderr: Should only log to stderr?\n",
            "    (default: 'false')\n",
            "  --[no]showprefixforinfo: If False, do not prepend prefix to info messages when\n",
            "    it's logged to stderr, --verbosity is set to INFO level, and python logging\n",
            "    is used.\n",
            "    (default: 'true')\n",
            "  --stderrthreshold: log messages at this level, or more severe, to stderr in\n",
            "    addition to the logfile.  Possible values are 'debug', 'info', 'warning',\n",
            "    'error', and 'fatal'.  Obsoletes --alsologtostderr. Using --alsologtostderr\n",
            "    cancels the effect of this flag. Please also note that this flag is subject\n",
            "    to --verbosity and requires logfile not be stderr.\n",
            "    (default: 'fatal')\n",
            "  -v,--verbosity: Logging verbosity level. Messages logged at this level or\n",
            "    lower will be included. Set to 1 for debug logging. If the flag was not set\n",
            "    or supplied, the value will be changed from the default of -1 (warning) to 0\n",
            "    (info) after flags are parsed.\n",
            "    (default: '-1')\n",
            "    (an integer)\n",
            "\n",
            "absl.testing.absltest:\n",
            "  --test_random_seed: Random seed for testing. Some test frameworks may change\n",
            "    the default value of this flag between runs, so it is not appropriate for\n",
            "    seeding probabilistic tests.\n",
            "    (default: '301')\n",
            "    (an integer)\n",
            "  --test_randomize_ordering_seed: If positive, use this as a seed to randomize\n",
            "    the execution order for test cases. If \"random\", pick a random seed to use.\n",
            "    If 0 or not set, do not randomize test case execution order. This flag also\n",
            "    overrides the TEST_RANDOMIZE_ORDERING_SEED environment variable.\n",
            "    (default: '')\n",
            "  --test_srcdir: Root of directory tree where source files live\n",
            "    (default: '')\n",
            "  --test_tmpdir: Directory for temporary testing files\n",
            "    (default: '/tmp/absl_testing')\n",
            "  --xml_output_file: File to store XML test results\n",
            "    (default: '')\n",
            "\n",
            "tensorflow.python.ops.parallel_for.pfor:\n",
            "  --[no]op_conversion_fallback_to_while_loop: If true, falls back to using a\n",
            "    while loop for ops for which a converter is not defined.\n",
            "    (default: 'false')\n",
            "\n",
            "tensorflow_hub.resolver:\n",
            "  --tfhub_cache_dir: If set, TF-Hub will download and cache Modules into this\n",
            "    directory. Otherwise it will attempt to find a network path.\n",
            "\n",
            "tensorflow_hub.tools.make_image_classifier.make_image_classifier:\n",
            "  --assert_accuracy_at_least: If set, the program fails if the validation\n",
            "    accuracy at the end of training is less than this number (between 0 and 1),\n",
            "    and no export of the trained model happens.\n",
            "    (a number)\n",
            "  --batch_size: Each training step samples a batch of this many images from the\n",
            "    training data. (You may need to shrink this when using a GPU and getting\n",
            "    out-of-memory errors. Avoid values below 8 when re-training modules that use\n",
            "    batch normalization.)\n",
            "    (default: '32')\n",
            "    (an integer)\n",
            "  --[no]do_fine_tuning: If set, the --tfhub_module is trained together with the\n",
            "    rest of the model being built.\n",
            "    (default: 'false')\n",
            "  --dropout_rate: The fraction of the input units to drop, used in dropout\n",
            "    layer.\n",
            "    (default: '0.2')\n",
            "    (a number)\n",
            "  --image_dir: A directory with subdirectories of images, one per class. If\n",
            "    unset, the TensorFlow Flowers example dataset will be used. Internally, the\n",
            "    dataset is split into training and validation pieces.\n",
            "  --image_size: The height and width of images to feed into --tfhub_module. (For\n",
            "    now, must be set manually for modules with variable input size.)\n",
            "    (an integer)\n",
            "  --labels_output_file: Where to save the labels (that is, names of image\n",
            "    subdirectories). The lines in this file appear in the same order as the\n",
            "    predictions of the model.\n",
            "  --learning_rate: The learning rate to use for gradient descent training.\n",
            "    (default: '0.005')\n",
            "    (a number)\n",
            "  --momentum: The momentum parameter to use for gradient descent training.\n",
            "    (default: '0.9')\n",
            "    (a number)\n",
            "  --saved_model_dir: The final model is exported as a SavedModel directory with\n",
            "    this name.\n",
            "  --[no]set_memory_growth: If flag is set, memory growth functionality flag will\n",
            "    be set as true for all GPUs prior to training. More details:\n",
            "    https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
            "    (default: 'false')\n",
            "  --tfhub_module: Which TF Hub module to use. Must be a module in TF2/SavedModel\n",
            "    format for computing image feature vectors.\n",
            "    (default:\n",
            "    'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')\n",
            "  --tflite_output_file: The final model is exported as a .tflite flatbuffers\n",
            "    file with this name.\n",
            "  --train_epochs: Training will do this many iterations over the dataset.\n",
            "    (default: '5')\n",
            "    (an integer)\n",
            "\n",
            "absl.flags:\n",
            "  --flagfile: Insert flag definitions from the given file into the command line.\n",
            "    (default: '')\n",
            "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
            "    the command line even if the program does not define a flag with that name.\n",
            "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
            "    format.\n",
            "    (default: '')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNsv6p8wYFHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d7ecbe0-37a5-473e-9f52-2ccf1ed5ea09"
      },
      "source": [
        "!unzip ./dataset.zip\n",
        "!rm -r ./dataset.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./dataset.zip\n",
            "  inflating: nishikino_maki/1.jpg    \n",
            "  inflating: nishikino_maki/10.jpg   \n",
            "  inflating: nishikino_maki/11.jpg   \n",
            "  inflating: nishikino_maki/12.jpg   \n",
            "  inflating: nishikino_maki/13.jpg   \n",
            "  inflating: nishikino_maki/14.jpg   \n",
            "  inflating: nishikino_maki/15.jpg   \n",
            "  inflating: nishikino_maki/16.jpg   \n",
            "  inflating: nishikino_maki/17.jpg   \n",
            "  inflating: nishikino_maki/18.jpg   \n",
            "  inflating: nishikino_maki/19.jpg   \n",
            "  inflating: nishikino_maki/2.jpg    \n",
            "  inflating: nishikino_maki/20.jpg   \n",
            "  inflating: nishikino_maki/21.jpg   \n",
            "  inflating: nishikino_maki/22.jpg   \n",
            "  inflating: nishikino_maki/23.jpg   \n",
            "  inflating: nishikino_maki/24.jpg   \n",
            "  inflating: nishikino_maki/25.jpg   \n",
            "  inflating: nishikino_maki/26.jpg   \n",
            "  inflating: nishikino_maki/27.jpg   \n",
            "  inflating: nishikino_maki/28.jpg   \n",
            "  inflating: nishikino_maki/29.jpg   \n",
            "  inflating: nishikino_maki/3.jpg    \n",
            "  inflating: nishikino_maki/30.jpg   \n",
            "  inflating: nishikino_maki/4.jpg    \n",
            "  inflating: nishikino_maki/5.jpg    \n",
            "  inflating: nishikino_maki/6.jpg    \n",
            "  inflating: nishikino_maki/7.jpg    \n",
            "  inflating: nishikino_maki/8.jpg    \n",
            "  inflating: nishikino_maki/9.jpg    \n",
            "  inflating: sakurauchi_riko/1.jpg   \n",
            "  inflating: sakurauchi_riko/10.jpg  \n",
            "  inflating: sakurauchi_riko/11.jpg  \n",
            "  inflating: sakurauchi_riko/12.jpg  \n",
            "  inflating: sakurauchi_riko/13.jpg  \n",
            "  inflating: sakurauchi_riko/14.jpg  \n",
            "  inflating: sakurauchi_riko/15.jpg  \n",
            "  inflating: sakurauchi_riko/16.jpg  \n",
            "  inflating: sakurauchi_riko/17.jpg  \n",
            "  inflating: sakurauchi_riko/18.jpg  \n",
            "  inflating: sakurauchi_riko/19.jpg  \n",
            "  inflating: sakurauchi_riko/2.jpg   \n",
            "  inflating: sakurauchi_riko/20.jpg  \n",
            "  inflating: sakurauchi_riko/21.jpg  \n",
            "  inflating: sakurauchi_riko/22.jpg  \n",
            "  inflating: sakurauchi_riko/23.jpg  \n",
            "  inflating: sakurauchi_riko/24.jpg  \n",
            "  inflating: sakurauchi_riko/25.jpg  \n",
            "  inflating: sakurauchi_riko/26.jpg  \n",
            "  inflating: sakurauchi_riko/27.jpg  \n",
            "  inflating: sakurauchi_riko/28.jpg  \n",
            "  inflating: sakurauchi_riko/29.jpg  \n",
            "  inflating: sakurauchi_riko/3.jpg   \n",
            "  inflating: sakurauchi_riko/30.jpg  \n",
            "  inflating: sakurauchi_riko/4.jpg   \n",
            "  inflating: sakurauchi_riko/5.jpg   \n",
            "  inflating: sakurauchi_riko/6.jpg   \n",
            "  inflating: sakurauchi_riko/7.jpg   \n",
            "  inflating: sakurauchi_riko/8.jpg   \n",
            "  inflating: sakurauchi_riko/9.jpg   \n",
            "  inflating: takimoto_hifumi/1.jpg   \n",
            "  inflating: takimoto_hifumi/10.jpg  \n",
            "  inflating: takimoto_hifumi/11.jpg  \n",
            "  inflating: takimoto_hifumi/12.jpg  \n",
            "  inflating: takimoto_hifumi/13.jpg  \n",
            "  inflating: takimoto_hifumi/14.jpg  \n",
            "  inflating: takimoto_hifumi/15.jpg  \n",
            "  inflating: takimoto_hifumi/16.jpg  \n",
            "  inflating: takimoto_hifumi/17.jpg  \n",
            "  inflating: takimoto_hifumi/18.jpg  \n",
            "  inflating: takimoto_hifumi/19.jpg  \n",
            "  inflating: takimoto_hifumi/2.jpg   \n",
            "  inflating: takimoto_hifumi/20.jpg  \n",
            "  inflating: takimoto_hifumi/21.jpg  \n",
            "  inflating: takimoto_hifumi/22.jpg  \n",
            "  inflating: takimoto_hifumi/23.jpg  \n",
            "  inflating: takimoto_hifumi/24.jpg  \n",
            "  inflating: takimoto_hifumi/25.jpg  \n",
            "  inflating: takimoto_hifumi/26.jpg  \n",
            "  inflating: takimoto_hifumi/27.jpg  \n",
            "  inflating: takimoto_hifumi/28.jpg  \n",
            "  inflating: takimoto_hifumi/29.jpg  \n",
            "  inflating: takimoto_hifumi/3.jpg   \n",
            "  inflating: takimoto_hifumi/30.jpg  \n",
            "  inflating: takimoto_hifumi/4.jpg   \n",
            "  inflating: takimoto_hifumi/5.jpg   \n",
            "  inflating: takimoto_hifumi/6.jpg   \n",
            "  inflating: takimoto_hifumi/7.jpg   \n",
            "  inflating: takimoto_hifumi/8.jpg   \n",
            "  inflating: takimoto_hifumi/9.jpg   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVVEQnoyYgTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3ad79e4-1b69-41f6-ac45-08d3247efd8d"
      },
      "source": [
        "!make_image_classifier \\\n",
        "  --image_dir dataset \\\n",
        "  --batch_size 15 \\\n",
        "  --tfhub_module https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 \\\n",
        "  --image_size 224 \\\n",
        "  --saved_model_dir anime-model \\\n",
        "  --labels_output_file class_labels.txt \\\n",
        "  --tflite_output_file anime-tflite-model.tflite"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-19 04:59:03.289391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "I0719 04:59:05.264416 140611373709184 resolver.py:79] Using /tmp/tfhub_modules to cache modules.\n",
            "2020-07-19 04:59:05.450814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-19 04:59:05.454144: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-07-19 04:59:05.454198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (4d7938ca6515): /proc/driver/nvidia/version does not exist\n",
            "2020-07-19 04:59:05.460377: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-19 04:59:05.460647: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2449100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-19 04:59:05.460687: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Using module https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with image size (224, 224)\n",
            "Found 20 images belonging to 4 classes.\n",
            "Found 80 images belonging to 4 classes.\n",
            "Found 4 classes: erza_scarlet, nishikino_maki, sakurauchi_riko, takimoto_hifumi\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 5124      \n",
            "=================================================================\n",
            "Total params: 2,263,108\n",
            "Trainable params: 5,124\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 3s 593ms/step - loss: 1.6688 - accuracy: 0.2769 - val_loss: 1.3305 - val_accuracy: 0.4667\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 1.1652 - accuracy: 0.5538 - val_loss: 0.5188 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 3s 541ms/step - loss: 0.7023 - accuracy: 0.8533 - val_loss: 0.5070 - val_accuracy: 0.9333\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.5746 - accuracy: 0.8923 - val_loss: 0.4837 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 2s 459ms/step - loss: 0.5861 - accuracy: 0.9231 - val_loss: 0.5008 - val_accuracy: 1.0000\n",
            "Done with training.\n",
            "Labels written to class_labels.txt\n",
            "2020-07-19 04:59:28.205516: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0719 04:59:29.693751 140611373709184 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: anime-model/assets\n",
            "I0719 04:59:31.252930 140611373709184 builder_impl.py:775] Assets written to: anime-model/assets\n",
            "SavedModel model exported to anime-model\n",
            "2020-07-19 04:59:34.765775: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2020-07-19 04:59:34.765957: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-07-19 04:59:34.870444: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
            "2020-07-19 04:59:34.870523: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1905 nodes (1640), 3230 edges (2965), time = 61.044ms.\n",
            "2020-07-19 04:59:34.870535: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 2.478ms.\n",
            "2020-07-19 04:59:36.358868: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2020-07-19 04:59:36.359040: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-07-19 04:59:36.614981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
            "2020-07-19 04:59:36.615051: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 790 nodes (-1115), 1851 edges (-1379), time = 183.191ms.\n",
            "2020-07-19 04:59:36.615063: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 790 nodes (0), 1851 edges (0), time = 24.698ms.\n",
            "I0719 04:59:36.665219 140611373709184 lite.py:509] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
            "TFLite model exported to anime-tflite-model.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL97E5dkai-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0bb76d8d-f12a-4b57-ceeb-ccbe177f3111"
      },
      "source": [
        "# Test with our own images!\n",
        "ARGS_INPUT_MEAN_DEFAULT = 127\n",
        "\n",
        "def load_labels(filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    return [line.strip() for line in f.readlines()]\n",
        "\n",
        "# First, load the TFLite model that we just created and allocate some tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path = \"anime-tflite-model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Second, get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# check the type of the input tensor\n",
        "floating_model = input_details[0]['dtype'] == np.float32\n",
        "\n",
        "# NxHxWxC, H:1, W:2\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "img = Image.open(\"31.jpg\").resize((width, height))\n",
        "\n",
        "# add N dim\n",
        "input_data = np.expand_dims(img, axis=0)\n",
        "\n",
        "if floating_model:\n",
        "  input_data = (np.float32(input_data) - ARGS_INPUT_MEAN_DEFAULT) / ARGS_INPUT_MEAN_DEFAULT\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "start_time = time.time()\n",
        "interpreter.invoke()\n",
        "stop_time = time.time()\n",
        "\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "results = np.squeeze(output_data)\n",
        "\n",
        "top_k = results.argsort()[-5:][::-1]\n",
        "labels = load_labels('class_labels.txt')\n",
        "  \n",
        "for i in top_k:\n",
        "  if floating_model:\n",
        "    print('{:08.6f}: {}'.format(float(results[i]), labels[i]))\n",
        "  else:\n",
        "    print('{:08.6f}: {}'.format(float(results[i] / 255.0), labels[i]))\n",
        "\n",
        "print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.566001: nishikino_maki\n",
            "0.320130: sakurauchi_riko\n",
            "0.096640: erza_scarlet\n",
            "0.017230: takimoto_hifumi\n",
            "time: 45.025ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYrnxk4hf6o6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2882990e-ea30-4156-8780-7adf14ce66a7"
      },
      "source": [
        "def recreate_labels():\n",
        "  # 1) We use this in order to ignore any hidden files that might be here.\n",
        "  labels = [folder for folder in os.listdir('datasets') if not folder.startswith('.')]\n",
        "  \n",
        "  # 2) Then, we output the contents of each folder name to a file.\n",
        "  with open('labels.txt', 'w') as file:\n",
        "    for label in labels:\n",
        "      file.write(label)\n",
        "      file.write('\\n')\n",
        "\n",
        "recreate_labels()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dandellions', 'tulips', 'roses', 'lilies']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}