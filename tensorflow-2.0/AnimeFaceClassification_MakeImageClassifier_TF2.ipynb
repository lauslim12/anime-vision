{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnimeFaceClassification_MakeImageClassifier_TF2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMtqFsJaXpvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install \"tensorflow~=2.0\"\n",
        "!pip install \"tensorflow-hub[make_image_classifier]~=0.6\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlRxeem0awGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "834880c2-ef2b-4dcf-ffb0-17a0ec631291"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNsv6p8wYFHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ./dataset.zip -d ./dataset\n",
        "!rm -r ./dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVVEQnoyYgTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dfc92a6-40b2-4b91-85e9-db75a52b3ed4"
      },
      "source": [
        "# Very good, but can still be more accurate!\n",
        "# DO NOT REMOVE THIS. I SPENT MULTIPLE HOURS SEARCHING FOR THE RIGHT ALGORITHM.\n",
        "!make_image_classifier \\\n",
        "  --image_dir dataset \\\n",
        "  --batch_size 16 \\\n",
        "  --saved_model_dir anime-model \\\n",
        "  --tfhub_module https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 \\\n",
        "  --image_size 224 \\\n",
        "  --labels_output_file class_labels.txt \\\n",
        "  --tflite_output_file anime-tflite-model.tflite \\\n",
        "  --train_epochs 10"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-20 10:37:45.070028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "I0720 10:37:47.027791 140039463036800 resolver.py:79] Using /tmp/tfhub_modules to cache modules.\n",
            "I0720 10:37:47.028540 140039463036800 resolver.py:413] Downloading TF-Hub Module 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'.\n",
            "I0720 10:37:47.382851 140039463036800 resolver.py:122] Downloaded https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4, Total size: 9.75MB\n",
            "I0720 10:37:47.383447 140039463036800 resolver.py:428] Downloaded TF-Hub Module 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'.\n",
            "2020-07-20 10:37:47.634436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-20 10:37:47.695982: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-07-20 10:37:47.696068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (58bcb2e7eed8): /proc/driver/nvidia/version does not exist\n",
            "2020-07-20 10:37:47.718827: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-20 10:37:47.719129: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2703100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-20 10:37:47.719188: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Using module https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with image size (224, 224)\n",
            "Found 27 images belonging to 3 classes.\n",
            "Found 108 images belonging to 3 classes.\n",
            "Found 3 classes: nishikino_maki, sakurauchi_riko, takimoto_hifumi\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 3843      \n",
            "=================================================================\n",
            "Total params: 2,261,827\n",
            "Trainable params: 3,843\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 4s 683ms/step - loss: 1.3985 - accuracy: 0.4130 - val_loss: 1.0382 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 1.0007 - accuracy: 0.6522 - val_loss: 0.7022 - val_accuracy: 0.8125\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 0.6228 - accuracy: 0.8261 - val_loss: 0.4178 - val_accuracy: 0.9375\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 4s 605ms/step - loss: 0.5648 - accuracy: 0.9271 - val_loss: 0.4558 - val_accuracy: 0.9375\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.4619 - accuracy: 0.9674 - val_loss: 0.4519 - val_accuracy: 0.9375\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 0.4407 - accuracy: 0.9891 - val_loss: 0.5165 - val_accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 3s 562ms/step - loss: 0.4399 - accuracy: 0.9896 - val_loss: 0.4492 - val_accuracy: 0.9375\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 0.4320 - accuracy: 0.9783 - val_loss: 0.4379 - val_accuracy: 0.9375\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 0.3833 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 0.3824 - accuracy: 0.9891 - val_loss: 0.4193 - val_accuracy: 1.0000\n",
            "Done with training.\n",
            "Labels written to class_labels.txt\n",
            "2020-07-20 10:38:36.226943: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0720 10:38:37.797478 140039463036800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: anime-model/assets\n",
            "I0720 10:38:39.482065 140039463036800 builder_impl.py:775] Assets written to: anime-model/assets\n",
            "SavedModel model exported to anime-model\n",
            "2020-07-20 10:38:43.305725: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2020-07-20 10:38:43.305911: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-07-20 10:38:43.415975: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
            "2020-07-20 10:38:43.416050: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1905 nodes (1640), 3230 edges (2965), time = 61.473ms.\n",
            "2020-07-20 10:38:43.416062: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 2.503ms.\n",
            "2020-07-20 10:38:44.948977: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2020-07-20 10:38:44.949217: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-07-20 10:38:45.271122: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
            "2020-07-20 10:38:45.271212: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 790 nodes (-1115), 1851 edges (-1379), time = 228.846ms.\n",
            "2020-07-20 10:38:45.271226: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 790 nodes (0), 1851 edges (0), time = 39.021ms.\n",
            "I0720 10:38:45.343775 140039463036800 lite.py:509] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
            "TFLite model exported to anime-tflite-model.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf-Ux9Eqzldj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e80a701-b9af-4cda-9a87-d60cad7e4dcd"
      },
      "source": [
        "# Arguments to test the model.\n",
        "ARGS_INPUT_MEAN = 127\n",
        "IMAGES_TO_TEST = ['46.jpg', '47.jpg', '48.jpg', '49.jpg', '50.jpg']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['46.jpg', '47.jpg', '48.jpg', '49.jpg', '50.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYdPBDNA0LCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load our label file.\n",
        "def load_labels(filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    return [line.strip() for line in f.readlines()]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "draAiTox0ACi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "5893ed3d-b92b-4f4a-e999-23080a79dae1"
      },
      "source": [
        "def test_images(IMAGE_TO_TEST):\n",
        "  for image_file in IMAGES_TO_TEST:\n",
        "    # First, load the TFLite model that we just created and allocate some tensors.\n",
        "    interpreter = tf.lite.Interpreter(model_path = \"anime-tflite-model.tflite\")\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Second, get input and output tensors.\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # check the type of the input tensor\n",
        "    floating_model = input_details[0]['dtype'] == np.float32\n",
        "\n",
        "    # NxHxWxC, H:1, W:2\n",
        "    height = input_details[0]['shape'][1]\n",
        "    width = input_details[0]['shape'][2]\n",
        "    img = Image.open(image_file).resize((width, height))\n",
        "\n",
        "    # add N dim\n",
        "    input_data = np.expand_dims(img, axis=0)\n",
        "\n",
        "    if floating_model:\n",
        "      input_data = (np.float32(input_data) - ARGS_INPUT_MEAN) / ARGS_INPUT_MEAN\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "    start_time = time.time()\n",
        "    interpreter.invoke()\n",
        "    stop_time = time.time()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    results = np.squeeze(output_data)\n",
        "\n",
        "    top_k = results.argsort()[-5:][::-1]\n",
        "    labels = load_labels('class_labels.txt')\n",
        "      \n",
        "    for i in top_k:\n",
        "      if floating_model:\n",
        "        print('{:08.6f}: {}'.format(float(results[i]), labels[i]))\n",
        "      else:\n",
        "        print('{:08.6f}: {}'.format(float(results[i] / 255.0), labels[i]))\n",
        "\n",
        "    print('Time: {:.3f}ms'.format((stop_time - start_time) * 1000))\n",
        "    print('\\n')\n",
        "\n",
        "test_images(IMAGE_TO_TEST)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.817392: takimoto_hifumi\n",
            "0.181480: sakurauchi_riko\n",
            "0.001128: nishikino_maki\n",
            "Time: 42.922ms\n",
            "\n",
            "\n",
            "0.841065: takimoto_hifumi\n",
            "0.140237: sakurauchi_riko\n",
            "0.018698: nishikino_maki\n",
            "Time: 36.472ms\n",
            "\n",
            "\n",
            "0.936330: takimoto_hifumi\n",
            "0.062487: sakurauchi_riko\n",
            "0.001183: nishikino_maki\n",
            "Time: 34.323ms\n",
            "\n",
            "\n",
            "0.666609: sakurauchi_riko\n",
            "0.331386: takimoto_hifumi\n",
            "0.002005: nishikino_maki\n",
            "Time: 35.564ms\n",
            "\n",
            "\n",
            "0.873141: takimoto_hifumi\n",
            "0.125340: sakurauchi_riko\n",
            "0.001518: nishikino_maki\n",
            "Time: 33.588ms\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}